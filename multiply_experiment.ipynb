{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f514e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplication Dataset (cot included/not, reverse/not)\n",
    "# - (no cot, no reverse) 11 x 12 = <answer> 132 \n",
    "# - (cot, no reverse) 11 x 12 = 12 + 120 = <answer> 132\n",
    "# - (no cot, reverse) 11 x 21 = <answer> 231 \n",
    "# - (cot, reverse) 11 x 21 = 21 + 021 = <answer> 231 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7693f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing components ---\n",
      "Model initialized on cpu with 28.34M parameters.\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from model.model_minimind import MiniMindConfig\n",
    "from model.model_sorl import SorlModelWrapper\n",
    "from dataset.base import MemLoader\n",
    "from src.sorl import SORLConfig\n",
    "import os \n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Configuration (Mimicking command-line args)\n",
    "# ==============================================================================\n",
    "args = SimpleNamespace(\n",
    "    # --- Paths ---\n",
    "    train_data_path=\"dataset/multiply/multiply_2x2_train.bin\",\n",
    "    val_data_path=\"dataset/multiply/multiply_2x2_val.bin\",\n",
    "    \n",
    "    # --- Model Config ---\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=4,\n",
    "    num_attention_heads=2,\n",
    "    abstract_vocab_sizes=\"8\",\n",
    "    \n",
    "    # --- Training Config ---\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    batch_size=128,\n",
    "    learning_rate=1e-4,\n",
    "    \n",
    "    # --- SORL Config ---\n",
    "    n_rollout=5,\n",
    "    temperature=1.0,\n",
    "    K=4,\n",
    "    denoise_steps=1,\n",
    "    max_t_search=0,\n",
    "    use_rhythmic_placeholders=True,\n",
    "    use_spike_placeholders=False,\n",
    "    use_special_placeholders=False,\n",
    "    special_token_id=31,\n",
    "    abstract_budget=5,\n",
    "    temperature_flip=False,\n",
    "    \n",
    "    # --- Curriculum and Memory ---\n",
    "    curriculum_ratio=0.6, # looks redundant as of now, it (vaguely) violates the \"compositionality\" principle\n",
    "    train_iterations=1000, # This will be used by the scheduler\n",
    "    use_fade_memory=False,\n",
    "    use_compression_mask=False, # <-- Set to True to test your new mask\n",
    "    compression_curriculum_ratio=0.25,\n",
    "    memory_span=128,\n",
    "    \n",
    "    # --- GAPT ---\n",
    "    default_phase=None, # Set to 1 or 2 to override, None to enable GAPT\n",
    "    delta=0.01,\n",
    "    tau=0.1,\n",
    "    p_m=10,\n",
    "    p_c=10\n",
    ")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Initialization\n",
    "# ==============================================================================\n",
    "print(\"--- Initializing components ---\")\n",
    "# --- Tokenizer and Data ---\n",
    "train_loader = MemLoader(args.train_data_path, device=args.device)\n",
    "val_loader = MemLoader(args.val_data_path, device=args.device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(train_loader.tokenizer_path) # data is tokenized\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# --- Model ---\n",
    "base_vocab_size = len(tokenizer)\n",
    "abstract_vocab_sizes = [int(v) for v in args.abstract_vocab_sizes.split(',')]\n",
    "full_vocab_list = [base_vocab_size] + abstract_vocab_sizes\n",
    "\n",
    "# 2 layer 4 head\n",
    "minimind_config = MiniMindConfig(\n",
    "    hidden_size=args.hidden_size,\n",
    "    num_attention_heads=args.num_attention_heads,\n",
    "    num_hidden_layers=args.num_hidden_layers,\n",
    "    vocab_size=sum(full_vocab_list)\n",
    ")\n",
    "\n",
    "model = SorlModelWrapper.from_scratch(\n",
    "    config=minimind_config,\n",
    "    full_vocab_size_list=full_vocab_list,\n",
    "    memory_span=args.memory_span,\n",
    "    pad_token_id=pad_token_id\n",
    ").to(args.device)\n",
    "\n",
    "print(f\"Model initialized on {args.device} with {sum(p.numel() for p in model.parameters())/1e6:.2f}M parameters.\")\n",
    "\n",
    "# --- SORL Config and Schedulers ---\n",
    "sorl_config = SORLConfig(\n",
    "    n=args.n_rollout, \n",
    "    temperature=args.temperature, \n",
    "    K=args.K,\n",
    "    l=1, \n",
    "    steps=args.denoise_steps, \n",
    "    max_t_search=args.max_t_search,\n",
    "    use_rhythmic_placeholders=args.use_rhythmic_placeholders,\n",
    "    use_spike_placeholders=args.use_spike_placeholders,\n",
    "    use_special_placeholders=args.use_special_placeholders,\n",
    "    special_token_id=args.special_token_id,\n",
    "    abstract_budget=args.abstract_budget,\n",
    "    temperature_flip=args.temperature_flip,\n",
    "    curriculum_ratio=args.curriculum_ratio,\n",
    "    use_fade_memory=args.use_fade_memory,\n",
    "    use_compression_mask=args.use_compression_mask,\n",
    "    min_keep=args.memory_span, \n",
    "    max_seq_len=train_loader.max_length,\n",
    "    train_iterations=args.train_iterations, \n",
    "    train_batch_size=args.batch_size,\n",
    "    val_batch_size=args.batch_size,\n",
    "    max_length=train_loader.max_length,\n",
    "    default_phase=args.default_phase, \n",
    "    delta=args.delta, tau=args.tau,\n",
    "    p_m=args.p_m, p_c=args.p_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76dce59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting interactive training loop ---\n",
      "Step 01 | Loss: 0.09 (SSL: 0.094, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 02 | Loss: 0.09 (SSL: 0.093, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 03 | Loss: 0.11 (SSL: 0.112, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 04 | Loss: 0.09 (SSL: 0.094, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 05 | Loss: 0.14 (SSL: 0.145, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 06 | Loss: 0.11 (SSL: 0.106, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 07 | Loss: 0.14 (SSL: 0.135, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 08 | Loss: 0.10 (SSL: 0.102, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 09 | Loss: 0.11 (SSL: 0.114, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 10 | Loss: 0.14 (SSL: 0.141, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.032 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 11 | Loss: 0.13 (SSL: 0.134, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.032 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 12 | Loss: 0.12 (SSL: 0.121, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.031 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 13 | Loss: 0.12 (SSL: 0.118, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.031 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 14 | Loss: 0.10 (SSL: 0.104, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 15 | Loss: 0.11 (SSL: 0.107, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.030 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 16 | Loss: 0.10 (SSL: 0.102, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.030 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 17 | Loss: 0.14 (SSL: 0.142, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.035 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 18 | Loss: 0.10 (SSL: 0.099, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.027 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 19 | Loss: 0.11 (SSL: 0.113, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.032 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 20 | Loss: 0.11 (SSL: 0.108, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.031 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 21 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 22 | Loss: 0.09 (SSL: 0.091, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.030 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 23 | Loss: 0.09 (SSL: 0.088, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.026 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 24 | Loss: 0.10 (SSL: 0.102, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.027 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 25 | Loss: 0.10 (SSL: 0.102, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.031 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 26 | Loss: 0.11 (SSL: 0.106, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.033 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 27 | Loss: 0.09 (SSL: 0.087, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 28 | Loss: 0.09 (SSL: 0.090, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.026 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 29 | Loss: 0.09 (SSL: 0.093, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.024 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 30 | Loss: 0.08 (SSL: 0.080, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.027 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 31 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 32 | Loss: 0.08 (SSL: 0.076, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.028 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 33 | Loss: 0.11 (SSL: 0.106, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.031 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 34 | Loss: 0.08 (SSL: 0.084, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 35 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 36 | Loss: 0.08 (SSL: 0.078, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 37 | Loss: 0.09 (SSL: 0.089, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.023 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 38 | Loss: 0.09 (SSL: 0.088, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.024 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 39 | Loss: 0.09 (SSL: 0.094, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.027 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 40 | Loss: 0.11 (SSL: 0.113, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.034 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 41 | Loss: 0.10 (SSL: 0.102, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.031 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 42 | Loss: 0.08 (SSL: 0.083, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.027 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 43 | Loss: 0.09 (SSL: 0.091, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.027 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 44 | Loss: 0.08 (SSL: 0.079, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.023 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 45 | Loss: 0.12 (SSL: 0.119, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.031 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 46 | Loss: 0.08 (SSL: 0.084, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -93.9% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 47 | Loss: 0.09 (SSL: 0.093, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.026 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 48 | Loss: 0.08 (SSL: 0.084, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 49 | Loss: 0.09 (SSL: 0.088, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.027 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 50 | Loss: 0.10 (SSL: 0.096, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 51 | Loss: 0.08 (SSL: 0.081, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.026 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 52 | Loss: 0.11 (SSL: 0.112, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.031 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 53 | Loss: 0.08 (SSL: 0.075, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 54 | Loss: 0.07 (SSL: 0.068, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 55 | Loss: 0.09 (SSL: 0.086, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.026 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 56 | Loss: 0.07 (SSL: 0.067, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 57 | Loss: 0.08 (SSL: 0.083, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.023 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 58 | Loss: 0.09 (SSL: 0.091, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.026 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 59 | Loss: 0.06 (SSL: 0.061, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 60 | Loss: 0.08 (SSL: 0.077, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 61 | Loss: 0.10 (SSL: 0.101, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.033 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 62 | Loss: 0.08 (SSL: 0.077, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 63 | Loss: 0.08 (SSL: 0.081, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 64 | Loss: 0.08 (SSL: 0.076, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.024 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 65 | Loss: 0.08 (SSL: 0.082, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 66 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.1% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 67 | Loss: 0.07 (SSL: 0.074, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 68 | Loss: 0.08 (SSL: 0.079, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 69 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 70 | Loss: 0.09 (SSL: 0.093, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 71 | Loss: 0.11 (SSL: 0.106, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.030 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 72 | Loss: 0.09 (SSL: 0.093, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.3% | Abs-Free-Loss: 0.028 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 73 | Loss: 0.08 (SSL: 0.079, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 74 | Loss: 0.08 (SSL: 0.076, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 75 | Loss: 0.08 (SSL: 0.081, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 76 | Loss: 0.08 (SSL: 0.076, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 77 | Loss: 0.09 (SSL: 0.091, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.029 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 78 | Loss: 0.07 (SSL: 0.075, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 79 | Loss: 0.08 (SSL: 0.076, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 80 | Loss: 0.08 (SSL: 0.075, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 81 | Loss: 0.07 (SSL: 0.068, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 82 | Loss: 0.07 (SSL: 0.068, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 83 | Loss: 0.11 (SSL: 0.112, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.030 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 84 | Loss: 0.09 (SSL: 0.093, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.028 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 85 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 86 | Loss: 0.09 (SSL: 0.086, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.030 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 87 | Loss: 0.07 (SSL: 0.075, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 88 | Loss: 0.08 (SSL: 0.083, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 89 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 90 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 91 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 92 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 93 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 94 | Loss: 0.07 (SSL: 0.073, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 95 | Loss: 0.07 (SSL: 0.075, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 96 | Loss: 0.10 (SSL: 0.099, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 97 | Loss: 0.07 (SSL: 0.073, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 98 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 99 | Loss: 0.07 (SSL: 0.072, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 100 | Loss: 0.09 (SSL: 0.087, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.026 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 101 | Loss: 0.07 (SSL: 0.067, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 102 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 103 | Loss: 0.09 (SSL: 0.086, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 104 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 105 | Loss: 0.06 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 106 | Loss: 0.08 (SSL: 0.082, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 107 | Loss: 0.08 (SSL: 0.079, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 108 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 109 | Loss: 0.06 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 110 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 111 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 112 | Loss: 0.11 (SSL: 0.108, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.027 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 113 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 114 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 115 | Loss: 0.07 (SSL: 0.071, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.9% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 116 | Loss: 0.07 (SSL: 0.068, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 117 | Loss: 0.06 (SSL: 0.063, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 118 | Loss: 0.09 (SSL: 0.087, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 119 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 120 | Loss: 0.10 (SSL: 0.097, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.026 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 121 | Loss: 0.08 (SSL: 0.075, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 122 | Loss: 0.06 (SSL: 0.063, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 123 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 124 | Loss: 0.07 (SSL: 0.075, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 125 | Loss: 0.08 (SSL: 0.084, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 126 | Loss: 0.07 (SSL: 0.074, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.023 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 127 | Loss: 0.10 (SSL: 0.103, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.029 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 128 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 129 | Loss: 0.08 (SSL: 0.082, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 130 | Loss: 0.07 (SSL: 0.074, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 131 | Loss: 0.06 (SSL: 0.058, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 132 | Loss: 0.06 (SSL: 0.064, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 133 | Loss: 0.07 (SSL: 0.067, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 134 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 135 | Loss: 0.06 (SSL: 0.059, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 136 | Loss: 0.07 (SSL: 0.072, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 137 | Loss: 0.07 (SSL: 0.074, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 138 | Loss: 0.07 (SSL: 0.074, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 139 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 140 | Loss: 0.06 (SSL: 0.061, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 141 | Loss: 0.06 (SSL: 0.058, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 142 | Loss: 0.08 (SSL: 0.075, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 143 | Loss: 0.05 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -86.5% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 144 | Loss: 0.05 (SSL: 0.055, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 145 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 146 | Loss: 0.05 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 147 | Loss: 0.08 (SSL: 0.079, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 148 | Loss: 0.08 (SSL: 0.081, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 149 | Loss: 0.09 (SSL: 0.091, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 150 | Loss: 0.06 (SSL: 0.059, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 151 | Loss: 0.07 (SSL: 0.070, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 152 | Loss: 0.06 (SSL: 0.065, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 153 | Loss: 0.07 (SSL: 0.069, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 154 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 155 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 156 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 157 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 158 | Loss: 0.07 (SSL: 0.072, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 159 | Loss: 0.06 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 160 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 161 | Loss: 0.09 (SSL: 0.093, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.023 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 162 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 163 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.6% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 164 | Loss: 0.06 (SSL: 0.063, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 165 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 166 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 167 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -95.1% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 168 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 169 | Loss: 0.06 (SSL: 0.059, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 170 | Loss: 0.08 (SSL: 0.085, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 171 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 172 | Loss: 0.07 (SSL: 0.073, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 173 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 174 | Loss: 0.07 (SSL: 0.070, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 175 | Loss: 0.07 (SSL: 0.068, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 176 | Loss: 0.09 (SSL: 0.086, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 177 | Loss: 0.06 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 178 | Loss: 0.05 (SSL: 0.051, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 179 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 180 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 181 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 182 | Loss: 0.03 (SSL: 0.034, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 183 | Loss: 0.08 (SSL: 0.084, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 184 | Loss: 0.07 (SSL: 0.069, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 185 | Loss: 0.08 (SSL: 0.083, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.8% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 186 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 187 | Loss: 0.03 (SSL: 0.030, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 188 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 189 | Loss: 0.06 (SSL: 0.065, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 190 | Loss: 0.06 (SSL: 0.059, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 191 | Loss: 0.09 (SSL: 0.087, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.024 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 192 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 193 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 194 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 195 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 196 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.1% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 197 | Loss: 0.06 (SSL: 0.058, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 198 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 199 | Loss: 0.07 (SSL: 0.073, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 200 | Loss: 0.08 (SSL: 0.082, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 201 | Loss: 0.08 (SSL: 0.085, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.025 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 202 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 203 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 204 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 205 | Loss: 0.06 (SSL: 0.063, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 206 | Loss: 0.05 (SSL: 0.052, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 207 | Loss: 0.09 (SSL: 0.090, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 208 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 209 | Loss: 0.08 (SSL: 0.078, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 210 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 211 | Loss: 0.06 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 212 | Loss: 0.02 (SSL: 0.025, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 213 | Loss: 0.08 (SSL: 0.079, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 214 | Loss: 0.09 (SSL: 0.086, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 215 | Loss: 0.08 (SSL: 0.080, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 216 | Loss: 0.08 (SSL: 0.077, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 217 | Loss: 0.08 (SSL: 0.076, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 218 | Loss: 0.06 (SSL: 0.064, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 219 | Loss: 0.07 (SSL: 0.075, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.6% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 220 | Loss: 0.06 (SSL: 0.059, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 221 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 222 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 223 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 224 | Loss: 0.07 (SSL: 0.070, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 225 | Loss: 0.12 (SSL: 0.118, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.028 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 226 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 227 | Loss: 0.07 (SSL: 0.069, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 228 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 229 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 230 | Loss: 0.09 (SSL: 0.095, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 231 | Loss: 0.07 (SSL: 0.068, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 232 | Loss: 0.04 (SSL: 0.035, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 233 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 234 | Loss: 0.08 (SSL: 0.083, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 235 | Loss: 0.05 (SSL: 0.055, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 236 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 237 | Loss: 0.06 (SSL: 0.064, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 238 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 239 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 240 | Loss: 0.08 (SSL: 0.080, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.1% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 241 | Loss: 0.05 (SSL: 0.046, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.4% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 242 | Loss: 0.08 (SSL: 0.083, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.022 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 243 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 244 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 245 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 246 | Loss: 0.08 (SSL: 0.080, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 247 | Loss: 0.07 (SSL: 0.069, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 248 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 249 | Loss: 0.08 (SSL: 0.078, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 250 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 251 | Loss: 0.06 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 252 | Loss: 0.07 (SSL: 0.074, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 253 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 254 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 255 | Loss: 0.07 (SSL: 0.073, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 256 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 257 | Loss: 0.05 (SSL: 0.051, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 258 | Loss: 0.07 (SSL: 0.068, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 259 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 260 | Loss: 0.05 (SSL: 0.052, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 261 | Loss: 0.04 (SSL: 0.035, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 262 | Loss: 0.06 (SSL: 0.059, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 263 | Loss: 0.04 (SSL: 0.035, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.1% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 264 | Loss: 0.05 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 265 | Loss: 0.07 (SSL: 0.074, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 266 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 267 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.8% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 268 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 269 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 270 | Loss: 0.07 (SSL: 0.069, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 271 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 272 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 273 | Loss: 0.03 (SSL: 0.032, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 274 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.3% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 275 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 276 | Loss: 0.06 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 277 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 278 | Loss: 0.02 (SSL: 0.019, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 279 | Loss: 0.10 (SSL: 0.099, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.023 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 280 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 281 | Loss: 0.06 (SSL: 0.063, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 282 | Loss: 0.03 (SSL: 0.026, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 283 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 284 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.6% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 285 | Loss: 0.06 (SSL: 0.063, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 286 | Loss: 0.06 (SSL: 0.058, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 287 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 288 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 289 | Loss: 0.07 (SSL: 0.073, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 290 | Loss: 0.07 (SSL: 0.072, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 291 | Loss: 0.03 (SSL: 0.031, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -93.1% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 292 | Loss: 0.04 (SSL: 0.038, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 293 | Loss: 0.07 (SSL: 0.072, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 294 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 295 | Loss: 0.03 (SSL: 0.034, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 296 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 297 | Loss: 0.02 (SSL: 0.024, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 298 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.8% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 299 | Loss: 0.06 (SSL: 0.055, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 300 | Loss: 0.08 (SSL: 0.076, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 301 | Loss: 0.03 (SSL: 0.033, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.1% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 302 | Loss: 0.06 (SSL: 0.058, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -86.8% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 303 | Loss: 0.05 (SSL: 0.051, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 304 | Loss: 0.06 (SSL: 0.063, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 305 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 306 | Loss: 0.05 (SSL: 0.046, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.3% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 307 | Loss: 0.05 (SSL: 0.052, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 308 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 309 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 310 | Loss: 0.06 (SSL: 0.059, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 311 | Loss: 0.05 (SSL: 0.046, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -86.5% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 312 | Loss: 0.07 (SSL: 0.070, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 313 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 314 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 315 | Loss: 0.09 (SSL: 0.093, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.026 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 316 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 317 | Loss: 0.06 (SSL: 0.063, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 318 | Loss: 0.04 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 319 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 320 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 321 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 322 | Loss: 0.08 (SSL: 0.079, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 323 | Loss: 0.07 (SSL: 0.070, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 324 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 325 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -94.5% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 326 | Loss: 0.06 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 327 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 328 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 329 | Loss: 0.06 (SSL: 0.059, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 330 | Loss: 0.09 (SSL: 0.086, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.024 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 331 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 332 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 333 | Loss: 0.06 (SSL: 0.058, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.8% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 334 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 335 | Loss: 0.06 (SSL: 0.064, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 336 | Loss: 0.07 (SSL: 0.067, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 337 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 338 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 339 | Loss: 0.04 (SSL: 0.038, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 340 | Loss: 0.08 (SSL: 0.075, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.4% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 341 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 342 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 343 | Loss: 0.06 (SSL: 0.064, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 344 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 345 | Loss: 0.06 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 346 | Loss: 0.05 (SSL: 0.046, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 347 | Loss: 0.02 (SSL: 0.021, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 348 | Loss: 0.07 (SSL: 0.074, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.023 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 349 | Loss: 0.07 (SSL: 0.070, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 350 | Loss: 0.06 (SSL: 0.065, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 351 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 352 | Loss: 0.06 (SSL: 0.063, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 353 | Loss: 0.03 (SSL: 0.030, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 354 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 355 | Loss: 0.04 (SSL: 0.036, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 356 | Loss: 0.07 (SSL: 0.073, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 357 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 358 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 359 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 360 | Loss: 0.08 (SSL: 0.083, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 361 | Loss: 0.06 (SSL: 0.064, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 362 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.4% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 363 | Loss: 0.03 (SSL: 0.034, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 364 | Loss: 0.06 (SSL: 0.061, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 365 | Loss: 0.05 (SSL: 0.045, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 366 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 367 | Loss: 0.05 (SSL: 0.052, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 368 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 369 | Loss: 0.02 (SSL: 0.022, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 370 | Loss: 0.03 (SSL: 0.028, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 371 | Loss: 0.09 (SSL: 0.085, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.3% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 372 | Loss: 0.04 (SSL: 0.036, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 373 | Loss: 0.08 (SSL: 0.082, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 374 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 375 | Loss: 0.01 (SSL: 0.013, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.005 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 376 | Loss: 0.07 (SSL: 0.068, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 377 | Loss: 0.06 (SSL: 0.061, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 378 | Loss: 0.10 (SSL: 0.095, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -87.3% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 379 | Loss: 0.05 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 380 | Loss: 0.05 (SSL: 0.052, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 381 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 382 | Loss: 0.08 (SSL: 0.080, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.020 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 383 | Loss: 0.05 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 384 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 385 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 386 | Loss: 0.03 (SSL: 0.035, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 387 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -94.8% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 388 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 389 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 390 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 391 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 392 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 393 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 394 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 395 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 396 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 397 | Loss: 0.05 (SSL: 0.045, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 398 | Loss: 0.05 (SSL: 0.051, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 399 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 400 | Loss: 0.07 (SSL: 0.071, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 401 | Loss: 0.06 (SSL: 0.055, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 402 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.9% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 403 | Loss: 0.04 (SSL: 0.041, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 404 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 405 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 406 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 407 | Loss: 0.04 (SSL: 0.041, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 408 | Loss: 0.06 (SSL: 0.059, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.6% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 409 | Loss: 0.05 (SSL: 0.046, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 410 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 411 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 412 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 413 | Loss: 0.08 (SSL: 0.079, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 414 | Loss: 0.06 (SSL: 0.064, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 415 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 416 | Loss: 0.03 (SSL: 0.033, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 417 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.6% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 418 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 419 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 420 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 421 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 422 | Loss: 0.08 (SSL: 0.080, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.9% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 423 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 424 | Loss: 0.05 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 425 | Loss: 0.06 (SSL: 0.059, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 426 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 427 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 428 | Loss: 0.09 (SSL: 0.094, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 429 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 430 | Loss: 0.06 (SSL: 0.061, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 431 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 432 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 433 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 434 | Loss: 0.03 (SSL: 0.035, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 435 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.6% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 436 | Loss: 0.03 (SSL: 0.033, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 437 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 438 | Loss: 0.05 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 439 | Loss: 0.03 (SSL: 0.028, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 440 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 441 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 442 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 443 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 444 | Loss: 0.09 (SSL: 0.089, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 445 | Loss: 0.08 (SSL: 0.076, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 446 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 447 | Loss: 0.04 (SSL: 0.035, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 448 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 449 | Loss: 0.03 (SSL: 0.030, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 450 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 451 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 452 | Loss: 0.08 (SSL: 0.081, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 453 | Loss: 0.06 (SSL: 0.061, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 454 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.8% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 455 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 456 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 457 | Loss: 0.05 (SSL: 0.046, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 458 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 459 | Loss: 0.03 (SSL: 0.033, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 460 | Loss: 0.03 (SSL: 0.034, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 461 | Loss: 0.08 (SSL: 0.075, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 462 | Loss: 0.07 (SSL: 0.067, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.8% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 463 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 464 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 465 | Loss: 0.06 (SSL: 0.058, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 466 | Loss: 0.06 (SSL: 0.059, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 467 | Loss: 0.09 (SSL: 0.086, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.023 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 468 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 469 | Loss: 0.06 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 470 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 471 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 472 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.9% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 473 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 474 | Loss: 0.05 (SSL: 0.052, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 475 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 476 | Loss: 0.06 (SSL: 0.064, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 477 | Loss: 0.09 (SSL: 0.086, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.021 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 478 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 479 | Loss: 0.05 (SSL: 0.051, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 480 | Loss: 0.04 (SSL: 0.038, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 481 | Loss: 0.04 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 482 | Loss: 0.07 (SSL: 0.069, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.6% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 483 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 484 | Loss: 0.06 (SSL: 0.064, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 485 | Loss: 0.05 (SSL: 0.051, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 486 | Loss: 0.05 (SSL: 0.051, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 487 | Loss: 0.05 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 488 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 489 | Loss: 0.04 (SSL: 0.041, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 490 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 491 | Loss: 0.05 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 492 | Loss: 0.07 (SSL: 0.074, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 493 | Loss: 0.05 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 494 | Loss: 0.07 (SSL: 0.074, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.023 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 495 | Loss: 0.07 (SSL: 0.067, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 496 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 497 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 498 | Loss: 0.04 (SSL: 0.035, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 499 | Loss: 0.06 (SSL: 0.064, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 500 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 501 | Loss: 0.06 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 502 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 503 | Loss: 0.05 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 504 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 505 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 506 | Loss: 0.01 (SSL: 0.013, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 507 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 508 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 509 | Loss: 0.08 (SSL: 0.083, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.018 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 510 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 511 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 512 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 513 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 514 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 515 | Loss: 0.05 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.8% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 516 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 517 | Loss: 0.07 (SSL: 0.072, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 518 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -94.5% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 519 | Loss: 0.03 (SSL: 0.030, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 520 | Loss: 0.05 (SSL: 0.051, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 521 | Loss: 0.03 (SSL: 0.026, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 522 | Loss: 0.05 (SSL: 0.050, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 523 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 524 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 525 | Loss: 0.03 (SSL: 0.033, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.1% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 526 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 527 | Loss: 0.07 (SSL: 0.072, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -86.5% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 528 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 529 | Loss: 0.05 (SSL: 0.052, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 530 | Loss: 0.07 (SSL: 0.072, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 531 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 532 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 533 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 534 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 535 | Loss: 0.09 (SSL: 0.091, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 536 | Loss: 0.07 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.3% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 537 | Loss: 0.07 (SSL: 0.067, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 538 | Loss: 0.08 (SSL: 0.075, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 539 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 540 | Loss: 0.05 (SSL: 0.052, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 541 | Loss: 0.04 (SSL: 0.038, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 542 | Loss: 0.04 (SSL: 0.038, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 543 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 544 | Loss: 0.08 (SSL: 0.077, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 545 | Loss: 0.06 (SSL: 0.065, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 546 | Loss: 0.07 (SSL: 0.066, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 547 | Loss: 0.05 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 548 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 549 | Loss: 0.03 (SSL: 0.033, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 550 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.5% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 551 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 552 | Loss: 0.05 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 553 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 554 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 555 | Loss: 0.07 (SSL: 0.071, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 556 | Loss: 0.06 (SSL: 0.064, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.015 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 557 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 558 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 559 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 560 | Loss: 0.03 (SSL: 0.030, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 561 | Loss: 0.04 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 562 | Loss: 0.04 (SSL: 0.041, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 563 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 564 | Loss: 0.03 (SSL: 0.029, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 565 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.017 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 566 | Loss: 0.04 (SSL: 0.041, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 567 | Loss: 0.08 (SSL: 0.083, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 568 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 569 | Loss: 0.05 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 570 | Loss: 0.03 (SSL: 0.032, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 571 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 572 | Loss: 0.05 (SSL: 0.046, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 573 | Loss: 0.03 (SSL: 0.032, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 574 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.8% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 575 | Loss: 0.04 (SSL: 0.038, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 576 | Loss: 0.04 (SSL: 0.038, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 577 | Loss: 0.03 (SSL: 0.031, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 578 | Loss: 0.06 (SSL: 0.057, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 579 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 580 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 581 | Loss: 0.05 (SSL: 0.049, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 582 | Loss: 0.05 (SSL: 0.052, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 583 | Loss: 0.03 (SSL: 0.026, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 584 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 585 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 586 | Loss: 0.03 (SSL: 0.033, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 587 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 588 | Loss: 0.05 (SSL: 0.054, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 589 | Loss: 0.04 (SSL: 0.036, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 590 | Loss: 0.04 (SSL: 0.036, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 591 | Loss: 0.07 (SSL: 0.074, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 592 | Loss: 0.04 (SSL: 0.038, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 593 | Loss: 0.03 (SSL: 0.033, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 594 | Loss: 0.05 (SSL: 0.046, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 595 | Loss: 0.03 (SSL: 0.028, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 596 | Loss: 0.07 (SSL: 0.069, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.019 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 597 | Loss: 0.04 (SSL: 0.045, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 598 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 599 | Loss: 0.02 (SSL: 0.022, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.005 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 600 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 601 | Loss: 0.03 (SSL: 0.033, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 602 | Loss: 0.03 (SSL: 0.025, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 603 | Loss: 0.04 (SSL: 0.036, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 604 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 605 | Loss: 0.03 (SSL: 0.025, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 606 | Loss: 0.03 (SSL: 0.032, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 607 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 608 | Loss: 0.03 (SSL: 0.025, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 609 | Loss: 0.02 (SSL: 0.022, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.8% | Abs-Free-Loss: 0.005 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 610 | Loss: 0.05 (SSL: 0.048, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 611 | Loss: 0.03 (SSL: 0.027, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.005 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 612 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.012 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 613 | Loss: 0.03 (SSL: 0.034, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 614 | Loss: 0.04 (SSL: 0.041, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 615 | Loss: 0.02 (SSL: 0.022, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.005 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 616 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 617 | Loss: 0.05 (SSL: 0.052, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 618 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 619 | Loss: 0.02 (SSL: 0.022, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 620 | Loss: 0.02 (SSL: 0.022, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 621 | Loss: 0.03 (SSL: 0.032, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 622 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 623 | Loss: 0.04 (SSL: 0.036, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.6% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 624 | Loss: 0.04 (SSL: 0.036, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 625 | Loss: 0.05 (SSL: 0.047, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.2% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 626 | Loss: 0.03 (SSL: 0.033, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 627 | Loss: 0.03 (SSL: 0.026, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 628 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 629 | Loss: 0.02 (SSL: 0.024, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.6% | Abs-Free-Loss: 0.005 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 630 | Loss: 0.03 (SSL: 0.031, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 631 | Loss: 0.03 (SSL: 0.027, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 632 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 633 | Loss: 0.03 (SSL: 0.026, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 634 | Loss: 0.07 (SSL: 0.068, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 635 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 636 | Loss: 0.06 (SSL: 0.060, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.013 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 637 | Loss: 0.03 (SSL: 0.025, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.3% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 638 | Loss: 0.03 (SSL: 0.035, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 639 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.9% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 640 | Loss: 0.06 (SSL: 0.058, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.014 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 641 | Loss: 0.03 (SSL: 0.026, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 642 | Loss: 0.04 (SSL: 0.038, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 643 | Loss: 0.03 (SSL: 0.028, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 644 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 645 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 646 | Loss: 0.03 (SSL: 0.029, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.4% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 647 | Loss: 0.04 (SSL: 0.035, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 648 | Loss: 0.05 (SSL: 0.053, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 649 | Loss: 0.02 (SSL: 0.022, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.004 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 650 | Loss: 0.06 (SSL: 0.056, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 651 | Loss: 0.03 (SSL: 0.034, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 652 | Loss: 0.03 (SSL: 0.031, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 653 | Loss: 0.03 (SSL: 0.026, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 654 | Loss: 0.02 (SSL: 0.020, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 655 | Loss: 0.03 (SSL: 0.030, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 656 | Loss: 0.03 (SSL: 0.035, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 657 | Loss: 0.03 (SSL: 0.031, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 658 | Loss: 0.02 (SSL: 0.017, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.1% | Abs-Free-Loss: 0.004 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 659 | Loss: 0.02 (SSL: 0.022, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 660 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.8% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 661 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 662 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 663 | Loss: 0.06 (SSL: 0.055, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 664 | Loss: 0.03 (SSL: 0.030, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.6% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 665 | Loss: 0.03 (SSL: 0.027, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 666 | Loss: 0.04 (SSL: 0.038, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 667 | Loss: 0.04 (SSL: 0.040, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 668 | Loss: 0.03 (SSL: 0.034, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 669 | Loss: 0.02 (SSL: 0.025, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 670 | Loss: 0.03 (SSL: 0.033, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 671 | Loss: 0.03 (SSL: 0.029, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 672 | Loss: 0.04 (SSL: 0.037, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 673 | Loss: 0.04 (SSL: 0.038, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -93.1% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 674 | Loss: 0.04 (SSL: 0.041, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 675 | Loss: 0.03 (SSL: 0.029, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 676 | Loss: 0.02 (SSL: 0.023, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 677 | Loss: 0.03 (SSL: 0.034, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.9% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 678 | Loss: 0.04 (SSL: 0.039, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.9% | Abs-Free-Loss: 0.011 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 679 | Loss: 0.03 (SSL: 0.028, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 680 | Loss: 0.04 (SSL: 0.044, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 681 | Loss: 0.04 (SSL: 0.036, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 682 | Loss: 0.04 (SSL: 0.041, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 683 | Loss: 0.03 (SSL: 0.028, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 684 | Loss: 0.02 (SSL: 0.017, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.005 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 685 | Loss: 0.03 (SSL: 0.034, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 686 | Loss: 0.05 (SSL: 0.046, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.009 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 687 | Loss: 0.03 (SSL: 0.032, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -92.2% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 688 | Loss: 0.01 (SSL: 0.013, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.1% | Abs-Free-Loss: 0.004 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 689 | Loss: 0.03 (SSL: 0.029, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.3% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 690 | Loss: 0.04 (SSL: 0.041, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 691 | Loss: 0.04 (SSL: 0.041, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -91.4% | Abs-Free-Loss: 0.008 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 692 | Loss: 0.03 (SSL: 0.031, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 693 | Loss: 0.04 (SSL: 0.043, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.2% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 694 | Loss: 0.03 (SSL: 0.030, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.1% | Abs-Free-Loss: 0.007 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 695 | Loss: 0.04 (SSL: 0.042, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -87.6% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 696 | Loss: 0.03 (SSL: 0.028, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -89.3% | Abs-Free-Loss: 0.005 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 697 | Loss: 0.02 (SSL: 0.016, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -88.5% | Abs-Free-Loss: 0.004 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 698 | Loss: 0.02 (SSL: 0.022, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.8% | Abs-Free-Loss: 0.006 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 699 | Loss: 0.06 (SSL: 0.062, Abs: 0.00) | Advantage: 0.0% | Info-Gain: -90.5% | Abs-Free-Loss: 0.016 | t_search: 0 | drop_ratio: 0.00\n",
      "Step 700 | Loss: 0.04 (SSL: 0.041, Abs: 0.00) | Advantage: -0.0% | Info-Gain: -88.8% | Abs-Free-Loss: 0.010 | t_search: 0 | drop_ratio: 0.00\n"
     ]
    }
   ],
   "source": [
    "from src.sorl import evaluate \n",
    "from src.sorl import compute_per_token_loss, compute_loss, sorl_search, SearchScheduler, GatedPhaseTransition\n",
    "\n",
    "# First, test out baseline performance, then test out SoRL performance etc.\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "search_scheduler = SearchScheduler(sorl_config)\n",
    "gapt = GatedPhaseTransition(sorl_config.delta, sorl_config.tau, sorl_config.p_m, sorl_config.p_c)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Interactive Training Loop\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Starting interactive training loop ---\")\n",
    "model.train()\n",
    "\n",
    "\n",
    "# for i in range(sorl_config.train_iterations): # Run for 10 steps\n",
    "for i in range(700):\n",
    "    # --- Scheduler Step ---\n",
    "    t_search, drop_ratio = search_scheduler.step()\n",
    "    sorl_config.max_t_search = 0\n",
    "    model.drop_ratio = 0.0\n",
    "\n",
    "    # --- Get data and perform SORL search ---\n",
    "    # (1). Apply loss mask (and change its shape with abs padding) || (2). Customize abs padding\n",
    "    data, loss_mask = train_loader.get_batch(sorl_config.train_batch_size)\n",
    "    with torch.no_grad():\n",
    "        search_data, switch_ratio = sorl_search(data, loss_mask, model, sorl_config)\n",
    "        \n",
    "    # --- Compute loss ---\n",
    "    ppt = compute_per_token_loss(model, search_data)\n",
    "    ssl_loss, abs_loss = compute_loss(search_data, model, ppt, loss_mask)\n",
    "    \n",
    "    total_loss = ssl_loss + abs_loss\n",
    "    \n",
    "    # --- Optimizer step ---\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # --- Logging ---\n",
    "    greedy_advantage, best_advantage, greedy_info_gain, _, a_loss = evaluate(data, loss_mask, sorl_config, model, search_n=1)\n",
    "    print(\n",
    "        f\"Step {i+1:02d} | \"\n",
    "        f\"Loss: {total_loss.item():.2f} (SSL: {ssl_loss.item():.3f}, Abs: {abs_loss.item():.2f}) | \"\n",
    "        f\"Advantage: {greedy_advantage:.1f}% | Info-Gain: {greedy_info_gain:.1f}% | Abs-Free-Loss: {a_loss:.3f} | \"\n",
    "        f\"t_search: {t_search} | \"\n",
    "        f\"drop_ratio: {model.drop_ratio:.2f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e1f7f",
   "metadata": {},
   "source": [
    "$\\textbf{Question} 1$. What'd happen if the topological similarity approaches 1, and how can we make it so?\n",
    "$\\textbf{Question} 2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b99adf",
   "metadata": {},
   "source": [
    "$\\textbf{Observation 1}$. 200 epochs is far from enough for minimid model to learn 2x2 multiplication. Think 2k epochs at least. We could also use a bigger batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131bbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Evaluation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Batches: 100%|| 20/20 [00:09<00:00,  2.17it/s, Accuracy=95.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Summary ---\n",
      "Samples Evaluated: 200\n",
      "Correct Predictions: 190\n",
      "Accuracy: 95.00%\n",
      "Topological Similarity: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 95.0,\n",
       " 'correct': 190,\n",
       " 'total': 200,\n",
       " 'top_sim_score': 0.8706793782852724}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval_multiply import evaluate_on_loader\n",
    "\n",
    "# --- Evaluation (Generate & Check Answer) ---- \n",
    "print(\"--- Running Evaluation ---\")\n",
    "evaluate_on_loader(model, tokenizer, val_loader, batch_size=10, K=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f285986",
   "metadata": {},
   "source": [
    "$\\textbf{Record 1.}$.  1.5 epochs (that's 80k * 1.5 = 120k data getting trained, with batch size of 128, roughly 1k iterations required) on 2x2 multiplication produces 66.5% accuracy on test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb81ac62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f497bd9d8c864343939c2cb8f8d3cc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca4191d80854b28bd67456b558d47d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 124,439,808\n",
      "Trainable parameters: 124,439,808\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "# Load the pretrained \"gpt2\" model (which is the 124M parameter version)\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# You can print the model architecture to see its layers\n",
    "# print(model)\n",
    "\n",
    "# To get the total number of parameters, you can do the following:\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "# And to see how many of those are trainable:\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43f2499d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b4952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dbc2b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 4 7 * 2 6 =\n",
      "Generated Response: <answer> 1 2 4 2 <eos> <eos> <eos> <eos> 2\n",
      "Expected Answer:  1 2 2 2\n",
      "Generated Answer: 1 2 4 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1 2 4 2', '1 2 2 2')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval_multiply import evaluate_multiplication\n",
    "\n",
    "input_ids, loss_mask = val_loader.get_batch(1)\n",
    "prompt = tokenizer.decode(input_ids[0])\n",
    "evaluate_multiplication(model, tokenizer, prompt, K=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a518ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate train_loader data is correct \n",
    "from eval_multiply import _get_query_and_gt_ids\n",
    "\n",
    "input_ids, loss_mask = train_loader.get_batch(1)\n",
    "prompt = tokenizer.decode(input_ids[0])\n",
    "\n",
    "query_str = prompt.split('=')[0].strip() # execute this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38792e8",
   "metadata": {},
   "source": [
    "$\\textbf{Idea 3}$. How about using RL instead? \n",
    "\n",
    "$\\textbf{Idea 4}$. How about using SoRL instead? \n",
    "\n",
    "$\\textbf{Idea 5}$. How about using SoRL + RL instead? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a8431a",
   "metadata": {},
   "source": [
    "Issue 1. Missing CoT generations. \n",
    "- $\\textit{Fix 1}$. Dynamically identify case requiring CoT and case that doesn't. \n",
    "\n",
    "Issue 2. I can't believe transformer can't learn multiplication (2 digits !?) -- Can we initialize a Qwen architecture and try on this again? Can we scale up the experiment script and run on GPU instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74b00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c6075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62cfe42d",
   "metadata": {},
   "source": [
    "$\\textbf{Issue 1}$. When including abstraction, the generated response don't 'stop' anymore. \n",
    "\n",
    "$\\textbf{Issue 2}$. Abstraction generation in 'train-time' mismatch with that of 'inference-time' (former is parallel search over query, latter is causal generation over answer).\n",
    "\n",
    "$\\textbf{Idea 1}$. We have mismatch between 'train-time' abstraction addition (which is on query), and 'test-time' abstraction addition (which is on answer). It's probably better to add abstraction on query, or prefix token sequence only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb46cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing components ---\n"
     ]
    }
   ],
   "source": [
    "from model.model_minimind import MiniMindConfig, MiniMindForCausalLM\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Initialization\n",
    "# ==============================================================================\n",
    "print(\"--- Initializing components ---\")\n",
    "# --- Tokenizer and Data ---\n",
    "train_loader = MemLoader(args.train_data_path, device=args.device)\n",
    "val_loader = MemLoader(args.val_data_path, device=args.device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(train_loader.tokenizer_path) # data is tokenized\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# --- Model ---\n",
    "base_vocab_size = len(tokenizer)\n",
    "abstract_vocab_sizes = [int(v) for v in args.abstract_vocab_sizes.split(',')]\n",
    "full_vocab_list = [base_vocab_size] + abstract_vocab_sizes\n",
    "\n",
    "# 2 layer 4 head\n",
    "minimind_config = MiniMindConfig(\n",
    "    hidden_size=args.hidden_size,\n",
    "    num_attention_heads=args.num_attention_heads,\n",
    "    num_hidden_layers=args.num_hidden_layers,\n",
    "    vocab_size=sum(full_vocab_list)\n",
    ")\n",
    "\n",
    "model = MiniMindForCausalLM(minimind_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1616a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting interactive training loop ---\n",
      "Step 01 | Loss: 1.24\n",
      "Step 02 | Loss: 1.39\n",
      "Step 03 | Loss: 1.21\n",
      "Step 04 | Loss: 1.34\n",
      "Step 05 | Loss: 1.36\n",
      "Step 06 | Loss: 1.30\n",
      "Step 07 | Loss: 1.32\n",
      "Step 08 | Loss: 1.23\n",
      "Step 09 | Loss: 1.22\n",
      "Step 10 | Loss: 1.26\n",
      "Step 11 | Loss: 1.28\n",
      "Step 12 | Loss: 1.20\n",
      "Step 13 | Loss: 1.22\n",
      "Step 14 | Loss: 1.17\n",
      "Step 15 | Loss: 1.18\n",
      "Step 16 | Loss: 1.23\n",
      "Step 17 | Loss: 1.21\n",
      "Step 18 | Loss: 1.16\n",
      "Step 19 | Loss: 1.26\n",
      "Step 20 | Loss: 1.13\n",
      "Step 21 | Loss: 1.13\n",
      "Step 22 | Loss: 1.24\n",
      "Step 23 | Loss: 1.12\n",
      "Step 24 | Loss: 1.23\n",
      "Step 25 | Loss: 1.11\n",
      "Step 26 | Loss: 1.11\n",
      "Step 27 | Loss: 1.17\n",
      "Step 28 | Loss: 1.21\n",
      "Step 29 | Loss: 1.19\n",
      "Step 30 | Loss: 1.20\n",
      "Step 31 | Loss: 1.26\n",
      "Step 32 | Loss: 1.18\n",
      "Step 33 | Loss: 1.15\n",
      "Step 34 | Loss: 1.09\n",
      "Step 35 | Loss: 1.14\n",
      "Step 36 | Loss: 1.16\n",
      "Step 37 | Loss: 1.05\n",
      "Step 38 | Loss: 1.12\n",
      "Step 39 | Loss: 1.20\n",
      "Step 40 | Loss: 1.06\n",
      "Step 41 | Loss: 1.18\n",
      "Step 42 | Loss: 1.14\n",
      "Step 43 | Loss: 1.11\n",
      "Step 44 | Loss: 1.17\n",
      "Step 45 | Loss: 1.19\n",
      "Step 46 | Loss: 1.11\n",
      "Step 47 | Loss: 1.05\n",
      "Step 48 | Loss: 1.14\n",
      "Step 49 | Loss: 1.19\n",
      "Step 50 | Loss: 1.17\n",
      "Step 51 | Loss: 1.12\n",
      "Step 52 | Loss: 1.12\n",
      "Step 53 | Loss: 1.16\n",
      "Step 54 | Loss: 1.19\n",
      "Step 55 | Loss: 1.17\n",
      "Step 56 | Loss: 1.18\n",
      "Step 57 | Loss: 1.08\n",
      "Step 58 | Loss: 1.14\n",
      "Step 59 | Loss: 1.08\n",
      "Step 60 | Loss: 1.19\n",
      "Step 61 | Loss: 1.09\n",
      "Step 62 | Loss: 1.08\n",
      "Step 63 | Loss: 1.01\n",
      "Step 64 | Loss: 1.16\n",
      "Step 65 | Loss: 1.11\n",
      "Step 66 | Loss: 1.09\n",
      "Step 67 | Loss: 1.11\n",
      "Step 68 | Loss: 1.09\n",
      "Step 69 | Loss: 1.08\n",
      "Step 70 | Loss: 1.07\n",
      "Step 71 | Loss: 1.13\n",
      "Step 72 | Loss: 1.07\n",
      "Step 73 | Loss: 1.09\n",
      "Step 74 | Loss: 1.12\n",
      "Step 75 | Loss: 0.98\n",
      "Step 76 | Loss: 1.04\n",
      "Step 77 | Loss: 1.06\n",
      "Step 78 | Loss: 1.08\n",
      "Step 79 | Loss: 1.12\n",
      "Step 80 | Loss: 1.06\n",
      "Step 81 | Loss: 1.11\n",
      "Step 82 | Loss: 1.12\n",
      "Step 83 | Loss: 1.10\n",
      "Step 84 | Loss: 1.03\n",
      "Step 85 | Loss: 1.09\n",
      "Step 86 | Loss: 1.11\n",
      "Step 87 | Loss: 1.11\n",
      "Step 88 | Loss: 1.15\n",
      "Step 89 | Loss: 1.11\n",
      "Step 90 | Loss: 1.09\n",
      "Step 91 | Loss: 1.15\n",
      "Step 92 | Loss: 1.12\n",
      "Step 93 | Loss: 1.08\n",
      "Step 94 | Loss: 1.19\n",
      "Step 95 | Loss: 0.99\n",
      "Step 96 | Loss: 1.09\n",
      "Step 97 | Loss: 1.11\n",
      "Step 98 | Loss: 1.17\n",
      "Step 99 | Loss: 1.16\n",
      "Step 100 | Loss: 1.08\n",
      "Step 101 | Loss: 1.11\n",
      "Step 102 | Loss: 1.21\n",
      "Step 103 | Loss: 1.11\n",
      "Step 104 | Loss: 1.00\n",
      "Step 105 | Loss: 1.09\n",
      "Step 106 | Loss: 1.09\n",
      "Step 107 | Loss: 1.03\n",
      "Step 108 | Loss: 1.04\n",
      "Step 109 | Loss: 1.16\n",
      "Step 110 | Loss: 1.02\n",
      "Step 111 | Loss: 1.04\n",
      "Step 112 | Loss: 1.09\n",
      "Step 113 | Loss: 1.13\n",
      "Step 114 | Loss: 1.15\n",
      "Step 115 | Loss: 1.03\n",
      "Step 116 | Loss: 1.12\n",
      "Step 117 | Loss: 1.07\n",
      "Step 118 | Loss: 1.07\n",
      "Step 119 | Loss: 1.05\n",
      "Step 120 | Loss: 1.02\n",
      "Step 121 | Loss: 0.97\n",
      "Step 122 | Loss: 1.04\n",
      "Step 123 | Loss: 1.09\n",
      "Step 124 | Loss: 1.09\n",
      "Step 125 | Loss: 1.09\n",
      "Step 126 | Loss: 1.04\n",
      "Step 127 | Loss: 1.06\n",
      "Step 128 | Loss: 1.04\n",
      "Step 129 | Loss: 1.08\n",
      "Step 130 | Loss: 1.07\n",
      "Step 131 | Loss: 1.06\n",
      "Step 132 | Loss: 0.99\n",
      "Step 133 | Loss: 1.05\n",
      "Step 134 | Loss: 1.10\n",
      "Step 135 | Loss: 1.03\n",
      "Step 136 | Loss: 1.01\n",
      "Step 137 | Loss: 1.00\n",
      "Step 138 | Loss: 0.96\n",
      "Step 139 | Loss: 0.99\n",
      "Step 140 | Loss: 1.04\n",
      "Step 141 | Loss: 1.01\n",
      "Step 142 | Loss: 1.01\n",
      "Step 143 | Loss: 1.06\n",
      "Step 144 | Loss: 1.08\n",
      "Step 145 | Loss: 0.99\n",
      "Step 146 | Loss: 0.99\n",
      "Step 147 | Loss: 1.06\n",
      "Step 148 | Loss: 1.07\n",
      "Step 149 | Loss: 1.03\n",
      "Step 150 | Loss: 0.99\n",
      "Step 151 | Loss: 1.06\n",
      "Step 152 | Loss: 1.08\n",
      "Step 153 | Loss: 0.96\n",
      "Step 154 | Loss: 1.03\n",
      "Step 155 | Loss: 1.00\n",
      "Step 156 | Loss: 1.05\n",
      "Step 157 | Loss: 0.97\n",
      "Step 158 | Loss: 0.96\n",
      "Step 159 | Loss: 1.04\n",
      "Step 160 | Loss: 1.00\n",
      "Step 161 | Loss: 1.09\n",
      "Step 162 | Loss: 1.02\n",
      "Step 163 | Loss: 1.00\n",
      "Step 164 | Loss: 0.98\n",
      "Step 165 | Loss: 0.96\n",
      "Step 166 | Loss: 1.04\n",
      "Step 167 | Loss: 1.02\n",
      "Step 168 | Loss: 1.02\n",
      "Step 169 | Loss: 1.02\n",
      "Step 170 | Loss: 0.97\n",
      "Step 171 | Loss: 1.02\n",
      "Step 172 | Loss: 1.12\n",
      "Step 173 | Loss: 1.08\n",
      "Step 174 | Loss: 1.02\n",
      "Step 175 | Loss: 1.02\n",
      "Step 176 | Loss: 1.07\n",
      "Step 177 | Loss: 1.07\n",
      "Step 178 | Loss: 0.96\n",
      "Step 179 | Loss: 1.11\n",
      "Step 180 | Loss: 1.02\n",
      "Step 181 | Loss: 0.97\n",
      "Step 182 | Loss: 1.02\n",
      "Step 183 | Loss: 1.04\n",
      "Step 184 | Loss: 1.10\n",
      "Step 185 | Loss: 1.05\n",
      "Step 186 | Loss: 1.09\n",
      "Step 187 | Loss: 1.01\n",
      "Step 188 | Loss: 1.06\n",
      "Step 189 | Loss: 0.97\n",
      "Step 190 | Loss: 1.06\n",
      "Step 191 | Loss: 1.07\n",
      "Step 192 | Loss: 1.04\n",
      "Step 193 | Loss: 0.95\n",
      "Step 194 | Loss: 1.08\n",
      "Step 195 | Loss: 1.04\n",
      "Step 196 | Loss: 1.02\n",
      "Step 197 | Loss: 1.06\n",
      "Step 198 | Loss: 1.05\n",
      "Step 199 | Loss: 1.12\n",
      "Step 200 | Loss: 1.08\n"
     ]
    }
   ],
   "source": [
    "from src.sorl import evaluate \n",
    "from src.sorl import compute_per_token_loss, compute_loss, sorl_search, SearchScheduler, GatedPhaseTransition\n",
    "\n",
    "# First, test out baseline performance, then test out SoRL performance etc.\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Interactive Training Loop\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Starting interactive training loop ---\")\n",
    "model.train()\n",
    "\n",
    "for i in range(sorl_config.train_iterations): # Run for 10 steps\n",
    "\n",
    "    # --- Get data and perform SORL search ---\n",
    "    # (1). Apply loss mask (and change its shape with abs padding) || (2). Customize abs padding\n",
    "    data, loss_mask = train_loader.get_batch(sorl_config.train_batch_size)\n",
    "    # break\n",
    "    # --- Compute loss ---\n",
    "    ppt = compute_per_token_loss(model, data, tokenizer.pad_token_id)\n",
    "    ssl_loss = (ppt * loss_mask[:, 1:]).sum() / loss_mask[:, 1:].sum()\n",
    "    total_loss = ssl_loss\n",
    "    \n",
    "    # --- Optimizer step ---\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # --- Logging ---\n",
    "    print(\n",
    "        f\"Step {i+1:02d} | \"\n",
    "        f\"Loss: {total_loss.item():.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d044737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
